# -*- coding: utf-8 -*-
"""2309

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ro_ErVTKkJrHKfDCShRU_NiuzEvcE9Po
"""

import pandas as pd
a=pd.read_csv('/content/credit_card_default.csv')
print(a)

a=a.drop(columns=['ID'],axis=1)
print(a)

import numpy as np
X = a[['LIMIT_BAL', 'AGE']].values
y = a['default payment_next_month'].values
print(X)
print(y)
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
theta = np.zeros(X.shape[1])
print(theta)
learning_rate = 0.01
num_epochs = 1000

# Training the logistic regression model
for epoch in range(num_epochs):
    # Calculate the hypothesis (predicted probabilities)
    z = np.dot(X, theta)
    h = sigmoid(z)
   # Calculate the gradient of the cost function
    gradient = np.dot(X.T, (h - y)) / len(y)
  # Update the parameters using gradient descent
    theta -= learning_rate * gradient
    # After training, 'theta' contains the learned coefficients

# Making predictions on new data
# Define the modified sigmoid function
def sigmoid(z):
    # Use np.clip to limit the range of z
    z = np.clip(z, -500, 500)  # You can adjust the range as needed
    return 1 / (1 + np.exp(-z))
def sigmoid(z):
    z = np.clip(z, -500, 500)  # Adjust the range as needed
    return 1 / (1 + np.exp(-z))
# Use the modified sigmoid function in your code
def predict(x_new, theta):
    probability = sigmoid(np.dot(x_new, theta))
    return 1 if probability >= 0.5 else 0
# Example prediction
new_feature1_value = 50000  # Example credit limit
new_feature2_value = 30     # Example age
new_data_point = np.array([new_feature1_value, new_feature2_value])
prediction = predict(new_data_point, theta)
print(f"Prediction:Â {prediction}")

def calculate_accuracy_and_errors(X, y, theta):
    # Calculate predicted probabilities
    predicted_probabilities = sigmoid(np.dot(X, theta))

    # Convert probabilities to binary predictions (0 or 1)
    predictions = (predicted_probabilities >= 0.5).astype(int)

    # Calculate accuracy
    accuracy = np.mean(predictions == y)

    # Calculate true positives, true negatives, false positives, and false negatives
    true_positives = np.sum((predictions == 1) & (y == 1))
    true_negatives = np.sum((predictions == 0) & (y == 0))
    false_positives = np.sum((predictions == 1) & (y == 0))
    false_negatives = np.sum((predictions == 0) & (y == 1))

    # Calculate precision, recall, and F1-score with checks to avoid division by zero
    if (true_positives + false_positives) > 0:
        precision = true_positives / (true_positives + false_positives)
    else:
        precision = 0.0

    if (true_positives + false_negatives) > 0:
        recall = true_positives / (true_positives + false_negatives)
    else:
        recall = 0.0

    if (precision + recall) > 0:
        f1_score = 2 * (precision * recall) / (precision + recall)
    else:
        f1_score = 0.0

    # Print the results
    print(f"Accuracy: {accuracy}")
    print(f"True Positives: {true_positives}")
    print(f"True Negatives: {true_negatives}")
    print(f"False Positives: {false_positives}")
    print(f"False Negatives: {false_negatives}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1 Score: {f1_score}")

# Call the function to calculate accuracy and errors
calculate_accuracy_and_errors(X, y, theta)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features (scaling)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
print(X_train)
print(X_test)

from sklearn.svm import SVC

# Create an SVM classifier
svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)

# Train the SVM model on the training data
svm_classifier.fit(X_train, y_train)
# Make predictions on the test data
y_pred = svm_classifier.predict(X_test)

# Calculate accuracy
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)

# Calculate minimum and maximum errors
min_error = 1.0 - accuracy
max_error = 1.0 - min_error

print(f"Accuracy: {accuracy}")
print(f"Minimum Error: {min_error}")
print(f"Maximum Error: {max_error}")

from sklearn.linear_model import Perceptron

# Create a Perceptron classifier
perceptron_classifier = Perceptron(max_iter=1000, random_state=42)

# Train the Perceptron model on the training data
perceptron_classifier.fit(X_train, y_train)
# Make predictions on the test data
y_pred = perceptron_classifier.predict(X_test)

# Calculate accuracy
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)

# Calculate minimum and maximum errors
min_error = 1.0 - accuracy
max_error = 1.0 - min_error

print(f"Accuracy: {accuracy}")
print(f"Minimum Error: {min_error}")
print(f"Maximum Error: {max_error}")

#the final code to find the  final output
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load the dataset (replace 'your_dataset.csv' with the actual dataset file)
data = pd.read_csv('/content/credit_card_default.csv')

# Define the feature matrix X and target vector y
X = data.drop('default payment_next_month', axis=1)  # Features
y = data['default payment_next_month']  # Target variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build a Random Forest Classifier (you can choose a different algorithm)
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the classifier
rf_classifier.fit(X_train, y_train)

# Make predictions on the test data
y_pred = rf_classifier.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Generate a classification report
class_report = classification_report(y_test, y_pred)
print("Classification Report:\n", class_report)

# Generate a confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_matrix)